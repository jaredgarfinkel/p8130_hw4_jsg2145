---
title: "p8130_hw4_jsg2145"
author: "Jared Garfinkel"
date: "11/16/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
	echo = FALSE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

##Problem 3

```{r}
brain <- readxl::read_excel("./Brain.xlsx") %>% 
  janitor::clean_names()
```

```{r}
non_hum <- brain %>% 
  filter(species != "Homo sapiens")
```

```{r}
non_hum %>% 
  lm(glia_neuron_ratio ~ ln_brain_mass, data = .)
```

## Problem 3a

```{r}
non_hum %>% 
  ggplot(aes(x = ln_brain_mass, y = glia_neuron_ratio)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y~x, se = FALSE)
```

```{r}
fit_1 <- non_hum %>% 
  lm(glia_neuron_ratio ~ ln_brain_mass, data = .)
```

```{r}
predict(fit_1, data.frame(ln_brain_mass = 7.22))
```
## Problem 3b

The predicted glia-neuron ratio for humans given the non human data is `r round(predict(fit_1, data.frame(ln_brain_mass = 7.22)), digits = 2)`.

## Problem 3c

The interval for the mean glia-neuron ratio at the given brain mass may make more 

sense given the data we have observed. An interval for a single new observation may

make more sense if we are interested in the predictive ability of our model.

## Problem 3d

$\hat{Y_h} = b_0 + b_1*X_h$

$$s^2(\hat{Y_h}) = MSE\left [\frac{1}{n} + \frac{(X_h-\bar{X})^2}{\sum{(X_i - \bar{X})^2}}\right]$$

```{r}
non_hum %>% 
  mutate(
    xbar = mean(ln_brain_mass),
    xdiff = ln_brain_mass - xbar,
    ybar = mean(glia_neuron_ratio),
    ydiff = glia_neuron_ratio - ybar) %>% 
  summarize(
    xdifftot = sum(xdiff^2),
    ydifftot = sum(ydiff^2),
    MSE = ydifftot/15
  )
```


$$s^2(\hat{Y_h}) = 0.0774*\left [ \frac{1}{17} + \frac{(7.22 - 4.29)^2}{22.21}\right]$$

= .0774 * `r 1/17 + ((7.22-4.29)^2/22.21)`

= `r .0774 * (1/17 + (7.22-4.29)^2/22.21)`

s = $\sqrt{s^2}$ = $\sqrt{.034} = `r sqrt(.034)`

95% CI: $$\hat{Y_h} \pm t_{1-\alpha/2,~n-2}*s(\hat{Y_H})$$

= 1.47 $\pm t_{.975,~15}*0.18$

= 1.47 $\pm$ `r qt(.975, 15)` * 0.18

= (`r 1.47 - qt(.975, 15)*0.18`,`r 1.47 + qt(.975, 15)*0.18`)

Since the human glia nueron ratio is within the 95% confidence interval of the predicted response

there is no evidence that the human brain has an excessive glia-neuron ratio compared with

other primates.

## Problem 3e

This is extrapolation since the prediction is outside the observed range. Extrapolation can 

provide accurate results when the prediction is close to the observed data. However, it may 

not be a good idea if the prediction is far from the observed data.

# Problem 4

##Problem 4a

```{r}
cost_df <- read_csv("./HeartDisease.csv") %>% 
  janitor::clean_names()
```

This dataset is `r nrow(cost_df)` rows long and `r ncol(cost_df)` columns across. It records 

observations about patients diagnosed with heart disease. The main variables are total cost and 

number of emergency room visits. Other variables of interest are age, gender, complications, and 

duration of treatment. Other variables includes the number of drugs prescribed, and the number of

comorbidities diagnosed.

```{r}
cost_df %>% 
  ggplot(aes(x = e_rvisits)) +
  geom_histogram(binwidth = 2)
```

```{r}
cost_df %>% 
  ggplot(aes(x = totalcost)) +
  geom_histogram(binwidth = 5000)
```

```{r}
cost_df %>% 
  ggplot(aes(x = duration)) +
  geom_histogram(binwidth = 30)
```

## Problem 4b

The values of total cost are not normally distributed. One applies a log transformation.

```{r}
cost_df %>% 
  mutate(
    ln_cost = log(totalcost)
  ) %>% 
  ggplot(aes(x = ln_cost)) +
  geom_histogram()
```

```{r}
cost_df %>% 
  mutate(
    comp_bin = if_else(complications == 0, 0, 1)
  )
```

## Problem 4c

Add variables for the log of total cost and comp_bin. Transform zeros in total cost to avoid 

infinite values by adding 0.5)

```{r}
nrml_df <- cost_df %>% 
  mutate(
    totalcost = ifelse(totalcost == 0, 0.5, totalcost),
    ln_cost = log(totalcost),
    comp_bin = if_else(complications == 0, 0, 1)    
  )
```

## Problem 4d

```{r}
nrml_df %>% 
  ggplot(aes(x = e_rvisits, y = ln_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_y_continuous(breaks = seq(0,12, by = 1))
```

```{r}
nrml_df %>% 
  lm(ln_cost ~ e_rvisits, data = .)
```

To interpret the slope, one back transforms the findings by raising the natural number, e, to the

power of the slope. There is an `r exp(.2256)` increase in cost associated with each emergency visit.

So, for a third visit, there would be an expected increase in cost of 3 * `r exp(.2256)` = `r 3*exp(.2256)`

compared with zero visits.

```{r}
fit <- nrml_df %>% 
  lm(ln_cost ~ e_rvisits, data = .)
```

```{r}
summary(fit)
```

This summary table shows the adjusted r-squared value is less than 0.1, indicating that the number of 

emergency room visits alone is a poor predictor for the total cost for a patient.

## Problem 4e

```{r}
fit2 <- nrml_df %>% 
  lm(ln_cost ~ e_rvisits + comp_bin, data = .)
```

```{r}
summary(fit2)
```

After back transforming on a log-scale, this summary table indicates that there is an `r exp(5.5+.2031)` 

increase in the total cost for a patient per emergency room visit and an average increase of `r exp(5.5+1.7166)` 

in the total cost if there is a complication during treatment.

### Problem 4ei

To determine whether complications are an effect modifier of the association of number of emergency

room visits with total cost, one determines if there is a significant difference in the estimated

slope: (.20311 - .22559)/.22559 = `r .20311 - .22559`/.22559 = `r (.20311 - .22559)/.22559`. A 

cutoff of ten percent is used, so this is not an effect modifier.

### Problem 4eii

To determine whether complications are a confounder of the relationship between number of emergency

room visits and total cost, there must be an association between the confounder and the exposure, 

being number of emergency room visits.

```{r}
fit3 <- nrml_df %>% 
  lm(e_rvisits ~ comp_bin, data = .)
```

```{r}
summary(fit3)
```

This summary table shows taht there is a 1.76 increase in the number of emergency room visits if

a complication occurs. However, the adjusted r-squared value indicates that a complication is a poor

predictor of the number of emergency room visits. So, complication is probably not a confounder.

### Problem 4eiii

Since a complication was close to the cutoff for being an effect modifier and it raises the

value of the adjusted r-squared by 50 percent in our model, it should be included in the model.

## Problem 4f

```{r}
fit4 <- nrml_df %>% 
  lm(ln_cost ~ e_rvisits +comp_bin + age + gender + duration, data = .)
```

```{r}
summary(fit4)
```

The MLR method using the variables for the number of emergency room visits, the presence of a

complication, age, gender, and duration of treatment raises the adjusted r-squared by a factor of 2.

While the number of emergency room visits, the presence of a complication and the duration of treatment

are associated with increased cost, age and being female are associated with a decrease in cost.

Since the model with the number of emergency room visits and complications accounts for nearly half

of the adjusted r-squared with three fewer variables, it may be more informative to include only these

two variables. Gender and age account for a relatively low proportion of the adjusted r-squared

in the log cost. While duration accounts for a significant portion of the adjusted r-squared, the

effect is very low - duration of treatment increases the price predictably, but at a very low rate.

There is a difficulty in accounting for the relationship between the number of emergency room visits

and complications because they are both categorical variables.